# LocalScribe - Human Summary

## Project Status
**Phase 2.1 - UI Refactor Complete** ‚úÖ Application UI successfully migrated to CustomTkinter with all visual and interaction improvements finalized, application stable and production-ready.

**Roadmap Established** ‚úÖ (2025-11-23) 5-phase development roadmap created and documented in TODO.md, aligned with official project specification. Covers document prioritization, parallel processing, system monitoring, model compatibility, and license integration.

**Code Patterns Refined** ‚úÖ (2025-11-25) Session 5 refined code patterns: Reverted Session 4's descriptive variable naming to more Pythonic variable reuse pattern with comprehensive logging. All transformation stages now use single `text` variable with 4-category logging (execution tracking, performance timing, text metrics, error details). Simpler code, better observability, trusts Python's GC. Updated PROJECT_OVERVIEW.md Section 12. All 50 core tests passing.

**UI Bugs Fixed & Vocabulary Workflow Integrated** ‚úÖ (2025-11-26) Session 6 fixed three user-reported GUI bugs: (1) file size rounding inconsistency (KB showing "1.5 KB" vs MB showing "2 MB" ‚Äî now all units round to integers), (2) model dropdown selection not persisting (selecting second Ollama model would reset to first ‚Äî now remembers user choice), (3) vocabulary extraction workflow completely missing (after documents processed, app would hang at "Processing complete" with no vocab extraction). Implemented async VocabularyWorker thread, fixed widget reference bug in queue_message_handler (was calling non-existent method on wrong widget), and added automatic spaCy model download. Resolved critical virtual environment PATH issue by using `sys.executable` instead of relying on `python` command resolution.

**Current Branch:** `main`
**Status:** üü° **Q&A SYSTEM INFRASTRUCTURE | SESSION 24** - Phase 1 complete (FAISS vector store), Phases 2-3 pending (UI & advanced features).

**Latest Session (2025-11-30 Session 24 - Q&A System with FAISS Vector Search):**
Implemented RAG-based Q&A infrastructure for legal documents. **Research:** Evaluated LlamaIndex (too heavy), ChromaDB (requires SQLite), selected **FAISS** for file-based persistence (no database needed for Windows installer). **Phase 1 Complete:** Created `src/vector_store/` package with VectorStoreBuilder, QARetriever, QuestionFlowManager. Vector store auto-creates after document extraction in background thread. Added branching question flow with 14 questions in `config/qa_questions.yaml` (court case ‚Üí criminal/civil ‚Üí specific questions). **Remaining:** Phase 2 (Q&A UI tab, QAWorker) and Phase 3 (auto-detect case type, smart suggestions, chat export). ~2 weeks remaining. All 51 tests passing.

**Previous Session (2025-11-29 Session 23 - Vocabulary CSV + Code Quality):**
Made vocabulary CSV usable (40-60% noise reduction): min occurrence filter, raised rarity threshold, OCR patterns, expanded blacklist. Added confidence columns (Quality Score, In-Case Freq, Freq Rank) hidden in GUI but configurable for CSV export. **Code Quality Quick Wins:** Cleaned up temp files + fixed `.gitignore`; replaced 9 print() with debug_log(); centralized 7 magic numbers to config.py (timeouts, pagination, chunk overlap); added settings input validation with user-friendly error messages. All 55 tests passing.

**Previous Session (2025-11-29 Session 22 - UI Improvements & Documentation Consolidation):**
Added user experience improvements: (1) "Generate X outputs" button now shows "Generating X outputs..." while processing, (2) Visible processing timer (‚è± 0:45 format) during operations, (3) Processing metrics logged to CSV for future ML duration prediction, (4) Status bar now 18pt bold bright cyan for better visibility, (5) Completion times now human-readable ("11m 20s" instead of "680.6s"). Consolidated documentation: merged scratchpad.md into TODO.md, updated CLAUDE.md Section 3.2 to reference TODO. Added high-priority brainstorming sections for vocabulary CSV quality and summary prompt quality improvements.

**Previous Session (2025-11-29 Session 21 Continued - Architecture Documentation):**
Created `ARCHITECTURE.md` with Mermaid diagrams documenting entire system architecture. Converted ASCII art diagrams to maintainable Mermaid format. Added mandatory architecture maintenance rules to `AI_RULES.md` Section 11D - diagrams must be updated when structure changes. Includes: High-Level Overview, UI Layer, Processing Pipeline, Multi-Document Summarization Pipeline (with actual prompt templates), AI Integration, Vocabulary Extraction, Parallel Processing, Configuration, Complete Data Flow, and File Directory.

**Previous Session (2025-11-29 Session 21 - Thread-Through Prompt Template Architecture):**
Fixed critical gap where multi-doc mode ignored user's selected prompt template. Implemented thread-through focus architecture: AI extracts focus areas (emphasis + instructions) from user's template, then threads them through all pipeline stages - chunk prompts, document final prompts, and meta-summary prompt. New modules: `src/prompt_focus_extractor.py` (FocusExtractor ABC + AIFocusExtractor), `src/prompt_adapters.py` (PromptAdapter ABC + MultiDocPromptAdapter). Key design: ALL templates use AI extraction (no hardcoded mappings), cache by content hash (edits trigger re-extraction), dependency injection for testability. 22 new tests, all passing.

**Previous Session (2025-11-29 Session 20 - Multi-Document Hierarchical Summarization):**
Fixed critical gap where multiple documents were naively concatenated and sent to Ollama (which silently truncated ~97% of content). Implemented hierarchical map-reduce: **Map Phase** processes each document in parallel through `ProgressiveDocumentSummarizer` (chunking ‚Üí chunk summaries ‚Üí document summary), **Reduce Phase** combines individual summaries into coherent meta-summary. New `src/summarization/` package with clean abstractions. `WorkflowOrchestrator` automatically routes: single doc ‚Üí fast direct path, multiple docs ‚Üí hierarchical path. 16 new tests, all passing.

**Previous Session (2025-11-28 Session 19 - Settings GUI + UI Polish):**
**Part A - Settings Dialog:** Implemented complete settings infrastructure with auto-generated tabbed UI. SettingsRegistry defines settings with metadata (type, default, min/max, getter/setter). SettingsDialog dynamically creates tabs per category with appropriate widgets (slider, checkbox, dropdown, spinbox). Four initial settings: summary length range (50-2000 words), temperature (0-2.0), auto-detect CPU cores, manual worker count. **Part B - UI Polish (User Feedback):** Fixed 4 user-reported issues: (1) **Tooltips not disappearing** - Added mouse position checking to hide tooltip when mouse leaves both icon and popup, (2) **Worker count always editable** - Added `set_enabled()` to SpinboxSetting and `_setup_dependencies()` to link checkbox state, (3) **More prominent tabs** - Enlarged tab buttons (size 14 bold, height 36) with custom colors, (4) **Better status bar visibility** - Made status label larger (size 14) and bold for readability. All 111 tests passing.

**Previous Session (2025-11-28 Session 16 - GUI Performance & Smart Preprocessing):**
**Part A - GUI Responsiveness:** Fixed unresponsive GUI after processing large documents. Implemented async batch insertion (20 rows/10ms yield), "Load More" pagination (50 rows per page), background garbage collection (non-blocking), optimized O(n log n) deduplication. **Part B - Smart Preprocessing Pipeline:** New modular preprocessing system for AI summaries. Four preprocessors: TitlePageRemover (score-based cover page detection), HeaderFooterRemover (frequency analysis), LineNumberRemover (1-25 at margins), QAConverter (Q./A. ‚Üí Question:/Answer:). Pipeline architecture supports easy addition/removal of preprocessors. All 71 tests passing.

**Previous Session (2025-11-28 Session 15 - Vocabulary Extraction Quality Improvements):**
Addressed poor vocabulary extraction quality after user review. Problems fixed: (1) **Common words in results** - "tests", "factors", "continued" now filtered via rarity checks on single-word entities. (2) **Wrong categorization** - ANDY CHOY no longer labeled as Place; added validation heuristics for person names vs organizations. (3) **Address fragments** - "NY 11354" filtered via ADDRESS_FRAGMENT_PATTERNS. (4) **Legal boilerplate** - "Answering Defendants" filtered via DOCUMENT_FRAGMENT_PATTERNS. (5) **Model upgrade** - Changed from en_core_web_sm (12MB) to en_core_web_lg (560MB) for ~4% better NER accuracy. (6) **Unknown category** - When classification is uncertain, shows "Unknown" instead of wrong category. (7) **UI fix** - Dropdown no longer shows "No outputs yet" placeholder after outputs generated. All 55 tests passing.

**Previous Session (2025-11-28 Session 14 - Vocabulary Extraction Performance Optimization):**
Fixed vocabulary extraction hanging on large documents. Implemented chunked processing with 50KB chunks, disabled unused spaCy components for ~3x speedup, added 15-second NLTK download timeout, fixed initialization order bug. All 55 tests passing.

**Previous Session (2025-11-28 Session 13 - GUI Responsiveness Improvements & Critical Issue Discovery):**
Implemented UI locking (slider/checkboxes disabled during processing), red cancel button (stops all workers, restores UI), batch queue processing (10 msgs/cycle to prevent "Not Responding"), configurable vocabulary display limits (150 default, 500 ceiling based on tkinter research). Fixed Path import bug in vocabulary_extractor. Identified GUI responsiveness issue with large PDFs that was subsequently traced to vocabulary extraction bottleneck (resolved in Session 14).

**Previous Session (2025-11-28 Session 12 - Development Log Automatic Condensation Policy):**
Established automatic condensation system for development_log.md using entry-count thresholds (not date-based): most recent 5 sessions keep full detail, sessions 6-20 condensed to 50-100 lines, sessions 21+ very condensed (20-30 lines). Updated AI_RULES.md Section 2 with condensation policy and created new Section 11 "End-of-Session Documentation Workflow" with 4-step process, condensation decision tree, and before/after examples. Current file: 894 lines (compliant). Benefits: consistent maintenance (no more ad-hoc "too big" requests), token efficiency, better AI context balance, works for both Claude and Gemini.

**Previous Session (2025-11-27 Sessions 10-11 - Vocabulary Extraction Bug Fixes & Advanced Filtering):**
**Session 10** fixed 5 critical bugs: (1) Common words bypassing filters - added frequency check for single-word NER entities and medical terms, (2) Threshold too low at 75K - increased to 150K, (3) ALL CAPS names mis-categorized - updated regex patterns `[a-z]+` ‚Üí `[a-zA-Z]+`, (4) Entity fragments - added `_clean_entity_text()` method, (5) Title abbreviations extracted - added `TITLE_ABBREVIATIONS` filter. **Session 11** added 6 advanced improvements: (1) Legal citation filtering (CPLR, Education Law patterns), (2) Legal boilerplate filtering (Verified Answer, Cause of Action), (3) Case citation filtering (X v. Y pattern), (4) Geographic code filtering (ZIP codes), (5) **Deduplication** - smart two-pass algorithm removes "Plaintiff XIANJUN LIANG" if "XIANJUN LIANG" exists, filters partial names, normalizes prefixes, (6) Law firm detection - correctly categorizes firms with ampersands and suffixes. Combined impact: 506 rows ‚Üí 50-80 rows.

**Previous Session (2025-11-27 Session 9 - Vocabulary Extraction Redesign for Stenographers):**
Completely redesigned vocabulary extraction to serve stenographer workflow needs. **Major architectural change:** Created modular `RoleDetectionProfile` system (`src/vocabulary/role_profiles.py`) enabling profession-specific behavior without core logic changes. Implemented `StenographerProfile` with context-aware pattern matching: detects "plaintiff John Smith" ‚Üí "Plaintiff", "Dr. Martinez" ‚Üí "Treating physician", "Lenox Hill Hospital" ‚Üí "Medical facility". Simplified categories from 7+ to 4 (Person/Place/Medical/Technical). Smart definitions: skip for people/places (stenographers need WHO/WHY, not dictionary meanings), provide for medical/technical terms. Enhanced regex filters for variations (`plaintiff(s)`, `defendants(s)`, possessives). Optimized rarity calculation: O(n) percentile ‚Üí O(1) cached rank lookup (sorts 333K dataset once). Updated UI column headers: "Category" ‚Üí "Type", "Relevance to Case" ‚Üí "Role/Relevance". CSV transformation example: "Dr. Sarah Martinez, Proper Noun (Person), High, N/A" ‚Üí "Dr. Sarah Martinez, Person, Treating physician, ‚Äî". Net code: 473 insertions, 615 deletions (-142 lines). All 5 vocabulary tests passing. Future-ready: adding `LawyerProfile` or `ParalegalProfile` requires only 50 lines of pattern definitions.

**Previous Session (2025-11-26 Session 8 Part 5 - Google Word Frequency Dataset Integration):**
Integrated Google's 333K word frequency dataset into vocabulary extraction to eliminate false positives like "plaintiff(s)", "defendant(s)", and other common-word variations. New methods: `_load_frequency_dataset()` (parses tab-separated word\tcount format), `_matches_variation_filter()` (regex-based filtering), `_is_word_rare_enough()` (frequency-based rarity checking), `_sort_by_rarity()` (sorts results: unknown words first, then lowest frequency counts). User-customizable configuration: `VOCABULARY_RARITY_THRESHOLD` (default 75K out of 333K) and `VOCABULARY_SORT_BY_RARITY` (toggle sorting). Extensible variation filters via regex patterns (e.g., `r'^[a-z]+\(s\)$'` for "(s)" variations). Gracefully falls back to WordNet if frequency file missing. All 55 tests passing, zero regressions.

**Previous Session (2025-11-26 Session 8 Part 3 - Prompt Selection UI Refinement):**
Refined prompt selection based on user feedback. The dropdown now shows ALL .txt prompt files equally without any "(Custom)" suffix distinction. Implemented underscore prefix convention: `_template.txt` (skeleton for users to copy) and `_README.txt` (comprehensive guide) are auto-created in user's prompts folder but excluded from dropdown. Renamed quadrant to "Model & Prompt Selection" and updated tooltips to guide users to create custom prompts. README includes quick start, required format, variable placeholders, and tips for effective prompts.

**Previous Session (2025-11-26 Session 8 Part 2 - Prompt Selection UI):**
New "Prompt Style" dropdown in Model Selection quadrant lets users choose between summarization styles. Implemented dual-directory system: built-in prompts ship with app in `config/prompts/` while user prompts persist through updates in `%APPDATA%\LocalScribe\prompts/`. User prompts with same name override built-in. Auto-creates skeleton template (`custom-template.txt`) on first run with instructions and required Phi-3 tokens. Fixed critical bug where model name was incorrectly used as prompt ID.

**Previous Session (2025-11-26 Session 8 Part 1 - System Monitor, Tooltips, Vocabulary Table):**
Three UI enhancements: **(1) System Monitor:** RAM now displays as percentage (51%) instead of GB, CPU and RAM have independent color indicators (CPU green while RAM yellow), both show "!" at 90%+. **(2) Tooltips:** Complete rewrite ‚Äî now position near mouse cursor (not fixed widget location), smart boundary detection flips tooltip if near screen edge, works correctly after window move/resize/maximize. **(3) Vocabulary Table:** Replaced CSV text display with Excel-like Treeview (frozen headers, scrollable content), added right-click "Exclude this term from future lists" with case-insensitive matching (excluding "New York" also blocks "NEW YORK"). User exclusions stored in `%APPDATA%\LocalScribe\config\user_vocab_exclude.txt`. All 55 tests passing.

**Previous Session (2025-11-26 Session 6 - UI Bug Fixes & Vocabulary Workflow Integration):**
Fixed three critical UI bugs. **Bug #1:** File size rounding inconsistency ‚Äî KB showed decimals (1.5 KB) while MB showed integers (2 MB). Fixed by unifying all units to use `round(size)`. **Bug #2:** Model dropdown selection wouldn't persist ‚Äî selecting second model in dropdown would reset to first. Fixed by implementing preference preservation logic in `refresh_status()`. **Bug #3:** Vocabulary extraction workflow completely missing ‚Äî after document processing completed, app would silently fail to start vocabulary extraction, hanging at "Processing complete". Root causes: (a) `queue_message_handler.py:87` called non-existent `get_output_options()` method on wrong widget (`summary_results`), (b) `en_core_web_sm` spaCy model not installed, (c) subprocess PATH resolution used `python` command instead of venv Python. Fixed all three issues: (a) Changed to direct widget access reading checkbox states from `self.main_window.output_options`, (b) Added `_load_spacy_model()` with auto-download capability, (c) Used `sys.executable` for subprocess to guarantee venv Python. Implemented VocabularyWorker class (background thread with graceful fallback for missing config files), added `_combine_documents()` helper to main window, made vocabulary extractor config files optional. All 3 git commits successful.

**Previous Session (2025-11-24 Session 2 - Code Refactoring, Documentation Cleanup, Bug Fixes & Testing):**
Completed major code quality improvements and documentation consolidation. Refactored main_window.py from 428 ‚Üí 290 lines (-32%) by extracting two new focused modules: quadrant_builder.py (UI layout, 221 lines) and queue_message_handler.py (async message routing, 156 lines). Consolidated redundant markdown files: deleted DEV_LOG.md, TODO.md, IN_PROGRESS.md, EDUCATION_INTERESTS.md, PREPROCESSING_PROPOSAL.md; fixed AI_RULES.md naming conflicts; merged PREPROCESSING_PROPOSAL into scratchpad (11 files ‚Üí 6 files, -45% reduction). Fixed critical Unicode encoding bug in debug logger that was crashing application. Discovered and documented HIGH-PRIORITY blocking issue: text extraction produces characters that Ollama cannot process (redacted content ‚ñà‚ñà, control chars, malformed UTF-8). Solution: Add Step 2.5 CharacterSanitizer pipeline before Phase 3 implementation. All code changes tested and verified; 4 git commits made.

**Session 2025-11-22 Improvements:**
1. **Tooltip System Redesign** - Implemented stable 500ms-delay tooltip system with proper event handling, eliminating flickering on all four help icons
2. **Menu Bar Dark Theme** - Changed menu bar from bright white to dark grey (#404040) matching CustomTkinter aesthetic
3. **Header Styling Enhancement** - Enlarged quadrant headers to 16pt bold and centered them for better visual hierarchy
4. **File Persistence** - Fixed issue where files disappeared during processing; they now remain visible with status updates
5. **Layout Reorganization** - Standardized all four quadrants with Row 0 (labels), Row 1 (icons), Row 2+ (content) structure
6. **Smart Tooltip Positioning** - Icons repositioned to top-left of quadrants with tooltips appearing to the right (ensures on-screen visibility)
7. **Consistent Icon Positioning** - All four help icons (üìÑ, ü§ñ, üìù, ‚öôÔ∏è) now positioned consistently for predictable UX

**CRITICAL BUG FIXES (Session 2025-11-17):**

1. **GUI Crash After Summary Display (Root Cause: Qt Threading Issue):**
   - **Problem:** Application crashed immediately after summary was generated and displayed, with no error message
   - **Root Cause:** `_on_summary_complete()` event handler was updating GUI widgets from AIWorker QThread (non-GUI thread). Qt requires all GUI updates from the main GUI thread.
   - **Solution:** Wrapped all GUI operations in comprehensive try-except with step-by-step logging
   - **Result:** Summaries now display reliably; errors shown gracefully instead of crashing

2. **Performance Logging Failure:**
   - **Problem:** Performance tracker calls were crashing the worker thread
   - **Solution:** Wrapped in try-except so performance logging failures don't crash the application
   - **Result:** Non-critical logging no longer affects core functionality

3. **UI Progress Display Cleanup:**
   - Removed "words so far" from progress indicator (legacy from streaming implementation)
   - Before: "Generating 100-word summary... (0:14 elapsed, 0 words so far)"
   - After: "Generating 100-word summary... (0:14 elapsed)"

**VERIFICATION:**
Created comprehensive test_ollama_workflow.py with 4 automated tests:
- Test 1: Ollama Connection ‚úì PASS
- Test 2: Model Availability ‚úì PASS (found gemma3:1b)
- Test 3: Prompt Templates ‚úì PASS (found 2 presets)
- Test 4: Summary Generation ‚úì PASS (171 words in 20.6s)

**Vocabulary Extractor Verification:**
Created tests/test_vocabulary_extractor.py with 5 automated tests:
- test_load_word_list ‚úì PASS
- test_is_unusual ‚úì PASS
- test_get_category ‚úì PASS
- test_get_definition ‚úì PASS
- test_extract ‚úì PASS

All integration tests passing. **Complete workflow now functional:**
1. Select documents ‚Üí Processing
2. Choose prompt template
3. Click Generate ‚Üí Ollama generates summary
4. **Summary displays in results panel**
5. User can copy to clipboard or save to file

**What Works ‚úÖ:**
- ‚úÖ **Hierarchical Meta-Summary Generation** - Generates an overall summary from individual document summaries to handle large inputs.
- ‚úÖ **Summary Options UI** - Controls for generating overall (meta) and per-document summaries with configurable lengths.
- ‚úÖ **Vocabulary Extraction UI Integration** - A checkbox to enable CSV export of unusual terms.
- ‚úÖ **Keyboard Shortcut for Generate Summaries** - Ctrl+G now triggers summary generation.
- ‚úÖ **Ollama service integration** with REST API calls
- ‚úÖ **Dynamic model dropdown** populated from Ollama available models
- ‚úÖ **Model pull functionality** - Download new models via UI (qwen2.5:7b, llama3.2:3b, etc.)
- ‚úÖ **Service health check** on startup with platform-specific instructions
- ‚úÖ **Prompt template selection** with dropdown and live preview
- ‚úÖ **Two analytical depth presets** (Factual Summary, Strategic Analysis)
- ‚úÖ **User preferences** - Save default prompt per model
- ‚úÖ **GUI remains fully responsive** during summary generation (no freezing!)
- ‚úÖ **Streaming token display** with real-time "Updated: HH:MM:SS" timestamps
- ‚úÖ **File selection** enables Generate button immediately (no need for "Select All")
- ‚úÖ **File metadata display** shows actual file sizes and page counts
- ‚úÖ **AI generation via Ollama** (qwen2.5:7b-instruct recommended, llama3.2:3b fallback)
- ‚úÖ **Heartbeat monitoring** (warns if worker process stalls)
- ‚úÖ **Comprehensive error handling** with user-friendly messages
- ‚úÖ **Process isolation** (worker crashes don't affect GUI)
- ‚úÖ **Cross-platform stability** (Windows, macOS, Linux - no DLL issues)
- ‚úÖ **Vocabulary Extraction Module** - Extracts unusual terms, categorizes, defines them, and assigns relevance based on category and frequency.

**Issues Resolved This Session (2025-11-16):**
- ‚úÖ **Generate Summary button** - Now enables intuitively after file selection
- ‚úÖ **File size/page display** - Fixed key name mismatch (pages‚Üípage_count, size_mb‚Üífile_size)
- ‚ö†Ô∏è **Progress dialog responsiveness** - Improved with event loop fix, may need further refinement
- ‚úÖ **Signal delivery** - Fixed checkbox state change signal timing in file table

**Local Development:** Activate the virtual environment: `.venv\Scripts\activate` (Windows) or `source .venv/bin/activate` (Mac/Linux)

---

## Development Roadmap (2025-11-23)

**Strategic direction established for Phases 2.2 through 5.** All items are documented in `TODO.md` with implementation estimates and technical specifications.

### Immediate Next Steps (Quick Wins - 1 hour each)
1. **Test Larger AI Models** - Pull `llama2:13b` and `mistral:7b` to test summary quality improvement. Hypothesis: 7B-13B models provide substantially better reasoning than 1B models currently in use.

### Planned Development Phases (15-20 hours total)

| Phase | Feature | Time | Status | Spec Section |
|-------|---------|------|--------|--------------|
| 2.2 | Document Prioritization System | 3-4 hrs | Planned | Section 6 |
| 2.5 | Parallel Document Processing | 4-5 hrs | Planned | New |
| 2.6 | System Monitor Widget (CPU/RAM) | 1-2 hrs | Planned | New |
| 2.7 | Model-Aware Prompt Formatting | 1-2 hrs | Planned | New |
| 3 | License Server Integration | 4-6 hrs | Planned | Section 4 |
| 4 | Vocabulary Definitions (Enhanced) | 2-3 hrs | Planned | Section 7.5.2, 8.2 |
| 5 | Advanced Features | TBD | Future | Post-v1.0 |

### Key Architecture Decisions (Locked In)

‚úÖ **Parallel Processing Design:**
- AsyncDocumentProcessor with queue-based job management
- User-controlled CPU allocation: 1/4, 1/2 (default), 3/4 cores
- Only meta-summary is blocking; all individual summaries process asynchronously
- Prevents system overload on shared machines

‚úÖ **System Transparency:**
- Real-time CPU% and RAM display in status bar
- Color-coded: Green (<50%), Yellow (50-75%), Red (75%+)
- Hover tooltip reveals CPU model, core count, clock speeds
- Helps users diagnose bottlenecks and optimize concurrency

‚úÖ **Model Compatibility:**
- All Ollama-downloaded models auto-discovered via `/api/tags`
- New `wrap_prompt_for_model()` detects model type and applies correct instruction format
- Supports Llama, Mistral, Gemma, Neural-Chat, Dolphin, and extensible for new models
- Enables users to freely experiment with different models without code changes

---

## File Directory

### Documentation Files
- **PROJECT_OVERVIEW.md** - Complete technical specification for LocalScribe (PRIMARY SOURCE OF TRUTH, 1148 lines)
- **ARCHITECTURE.md** - **NEW (Session 21)** Living program architecture with Mermaid diagrams (view with `Ctrl+Shift+V` in VS Code)
- **AI_RULES.md** - AI engineering partner instructions (UPDATED Session 21: Section 11D architecture diagram maintenance rules)
- **development_log.md** - Timestamped log of all code changes and features
- **human_summary.md** - This file; high-level status report for human consumption
- **TODO.md** - Backlog of future features, improvements, and ideas (merged from scratchpad.md)
- **README.md** - Project overview with installation and usage instructions
- **ONNX_MIGRATION_LOG.md** - Comprehensive technical log of ONNX Runtime migration (historical reference)

### Data Files
- **Word_rarity-count_1w.txt** - Google word frequency dataset (333,333 words, tab-separated format: word\tfrequency_count) - NEW in Session 8 Part 5

### Source Code
- **src/main.py** - Desktop GUI application entry point (uses CustomTkinter)
- **src/config.py** - Centralized configuration constants (file paths, limits, settings, model names, vocabulary rarity threshold and sorting)
- **src/logging_config.py** - **NEW (Session 7)** Unified logging system (260 lines) - single source of truth for debug_log, info, warning, error, Timer
- **src/debug_logger.py** - Backward compatibility wrapper - re-exports from logging_config.py
- **src/prompt_config.py** - User-configurable AI prompt parameters loader (singleton pattern)
- **src/prompt_template_manager.py** - Prompt template discovery, loading, validation, and formatting system
- **src/user_preferences.py** - User preferences manager (saves default prompts per model to JSON)
- **src/extraction/raw_text_extractor.py** (~700 lines) - Raw text extraction module (Steps 1-2 of pipeline): PDF/TXT/RTF extraction, OCR, basic text normalization, case number extraction, and progress callbacks
- **src/sanitization/character_sanitizer.py** - Character sanitization module (Step 2.5 of pipeline): Unicode normalization, mojibake fix, redaction handling
- **src/vocabulary/** - **NEW (Session 7), MAJOR REFACTOR (Session 9)** Vocabulary extraction package
  - **src/vocabulary/__init__.py** - Package init, exports VocabularyExtractor
  - **src/vocabulary/vocabulary_extractor.py** (600+ lines) - Extracts unusual terms using spaCy NER, NLTK WordNet, Google word frequency dataset with O(1) cached rarity lookups, and **NEW (Session 9)** modular role detection via profiles
  - **src/vocabulary/role_profiles.py** (280 lines) - **NEW (Session 9)** Modular profession-specific role detection system: RoleDetectionProfile base class, StenographerProfile implementation with pattern-based context matching, placeholders for future LawyerProfile/ParalegalProfile
- **src/ai/ollama_model_manager.py** - PRIMARY: Ollama REST API model manager (uses HTTP to communicate with local Ollama service)
- **src/ai/summary_post_processor.py** - **NEW (Session 8 Part 4)** Backend-agnostic summary length enforcement (199 lines) - uses dependency injection to work with any text generation function
- **src/ai/onnx_model_manager.py** - DEPRECATED: ONNX Runtime GenAI model manager (kept for reference)
- **src/ai/model_manager.py** - DEPRECATED: llama-cpp-python model manager (kept for reference only)
- **src/ai/__init__.py** - AI package initialization (exports OllamaModelManager as default ModelManager)
- **src/ui/main_window.py** (295 lines) - Main application window, coordinates orchestrator and message handler
- **src/ui/workflow_orchestrator.py** - **NEW (Session 7)** Workflow logic (180 lines) - decides workflow steps, manages state
- **src/ui/queue_message_handler.py** (210 lines) - Message routing and UI updates only (separation of concerns)
- **src/ui/widgets.py** (209 lines) - Custom widgets: FileReviewTable, ModelSelectionWidget, OutputOptionsWidget
- **src/ui/workers.py** - Background workers (ProcessingWorker, VocabularyWorker, OllamaAIWorkerManager)
- **src/ui/dialogs.py** - Progress dialogs (ModelLoadProgressDialog with timer, SimpleProgressDialog)
- **src/ui/processing_timer.py** - **NEW (Session 22)** Processing timer widget, CSV metrics logging, and `format_duration()` utility function
- **src/ui/system_monitor.py** - Real-time CPU/RAM display widget with independent color indicators and hover tooltip
- **src/ui/dynamic_output.py** - **UPDATED (Session 8)** Dynamic output display with Excel-like vocabulary Treeview and right-click exclusion menu
- **src/ui/tooltip_helper.py** - **REWRITTEN (Session 8)** Mouse-relative tooltip positioning with boundary detection
- **src/ui/settings/** - **NEW (Session 19)** Settings subsystem package
  - **src/ui/settings/__init__.py** - Package init, exports SettingsDialog
  - **src/ui/settings/settings_registry.py** - SettingsRegistry singleton with setting definitions (type, default, min/max, getter/setter)
  - **src/ui/settings/settings_dialog.py** - Tabbed settings dialog with auto-generated UI from registry metadata
  - **src/ui/settings/settings_widgets.py** - Custom widgets: TooltipIcon, SliderSetting, CheckboxSetting, DropdownSetting, SpinboxSetting
- **src/ui/__init__.py** - UI package initialization
- **src/utils/__init__.py** - Utils package initialization, re-exports logging functions
- **src/utils/logger.py** - Backward compatibility wrapper - re-exports from logging_config.py
- **src/utils/text_utils.py** - Shared text utilities - combine_document_texts() with optional preprocessing
- **src/preprocessing/** - **NEW (Session 16)** Smart preprocessing pipeline for AI summaries
  - **src/preprocessing/__init__.py** - Package init, exports all preprocessors and create_default_pipeline()
  - **src/preprocessing/base.py** - BasePreprocessor abstract class and PreprocessingPipeline orchestrator
  - **src/preprocessing/line_number_remover.py** - Removes transcript line numbers (1-25) from margins
  - **src/preprocessing/header_footer_remover.py** - Removes repetitive headers/footers using frequency analysis
  - **src/preprocessing/title_page_remover.py** - Removes cover pages using score-based detection
  - **src/preprocessing/qa_converter.py** - Converts Q./A. notation to Question:/Answer: format
- **src/summarization/** - **NEW (Session 20)** Multi-document hierarchical summarization package
  - **src/summarization/__init__.py** - Package exports
  - **src/summarization/result_types.py** - `DocumentSummaryResult`, `MultiDocumentSummaryResult` dataclasses
  - **src/summarization/document_summarizer.py** - `DocumentSummarizer` ABC + `ProgressiveDocumentSummarizer` wrapper (UPDATED Session 21: accepts prompt_adapter)
  - **src/summarization/multi_document_orchestrator.py** - Parallel document processing with map-reduce pattern (UPDATED Session 21: accepts prompt_adapter)
- **src/prompt_focus_extractor.py** - **NEW (Session 21)** Extracts focus areas from prompt templates using AI; `FocusExtractor` ABC + `AIFocusExtractor` with content-hash caching
- **src/prompt_adapters.py** - **NEW (Session 21)** Generates stage-specific prompts with focus emphasis; `PromptAdapter` ABC + `MultiDocPromptAdapter` for thread-through architecture
- **src/performance_tracker.py** - Performance tracking for time estimates
- **src/__init__.py** - Package initialization

### Tests
- **tests/test_raw_text_extractor.py** (24 unit tests - ALL PASSING) - Comprehensive test coverage for RawTextExtractor (Steps 1-2)
- **tests/test_preprocessing.py** - **NEW (Session 16)** 16 tests for preprocessing pipeline and all 4 preprocessors
- **tests/test_multi_document_summarization.py** - **NEW (Session 20)** 16 tests for hierarchical map-reduce summarization
- **tests/test_prompt_adapters.py** - **NEW (Session 21)** 22 tests for focus extraction and prompt adapters (ABC contracts, caching, parsing)
- **tests/sample_docs/test_complaint.txt** - Sample legal document for testing
- **tests/sample_docs/test_motion.rtf** - Sample RTF legal document for testing
- **tests/output/** - Test output directory (gitignored)

### Configuration
- **config/prompt_parameters.json** - User-editable AI settings (word count, temperature, top-p, etc.)
- **config/prompts/phi-3-mini/factual-summary.txt** - Objective fact-focused summary template
- **config/prompts/phi-3-mini/strategic-analysis.txt** - Deep analytical summary template
- **config/user_preferences.json** - User's saved default prompts per model (auto-created)
- **requirements.txt** - Python dependencies including onnxruntime-genai-directml, huggingface-hub, numpy<2.0
- **.gitignore** - Git ignore rules (venv/, cleaned/, *.log, etc.)
- **venv/** - Virtual environment (NOT in git, auto-created by session-start hook)
- **.claude/hooks/session-start.sh** - Auto-setup script (browser only, skips on Windows)
- **.claude/settings.local.json** - Local permissions configuration (not committed)

### Claude Code Browser Environment
- **Session-Start Hook:** Automatically installs Tesseract OCR, creates venv, installs all dependencies, downloads NLTK data
- **Zero Setup:** New browser sessions are instantly ready to run tests and process documents
- **Cached State:** Container caching makes subsequent sessions start in seconds

## Planned Future Directory Structure (v3.0)

When implementing the remaining pipeline steps, the codebase will be reorganized as:

```
src/
‚îú‚îÄ‚îÄ extraction/           (Steps 1-2: ‚úÖ Implemented)
‚îÇ   ‚îú‚îÄ‚îÄ raw_text_extractor.py
‚îÇ   ‚îî‚îÄ‚îÄ __init__.py
‚îÇ
‚îú‚îÄ‚îÄ preprocessing/        (Step 3: Planned)
‚îÇ   ‚îú‚îÄ‚îÄ base.py
‚îÇ   ‚îú‚îÄ‚îÄ pipeline.py
‚îÇ   ‚îú‚îÄ‚îÄ basic/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ocr_error_fixer.py
‚îÇ   ‚îî‚îÄ‚îÄ smart/
‚îÇ       ‚îú‚îÄ‚îÄ line_number_remover.py
‚îÇ       ‚îú‚îÄ‚îÄ header_footer_remover.py
‚îÇ       ‚îî‚îÄ‚îÄ ...
‚îÇ
‚îú‚îÄ‚îÄ vocabulary/          (Step 4: Planned)
‚îÇ   ‚îî‚îÄ‚îÄ text_vocabulary_extractor.py
‚îÇ
‚îú‚îÄ‚îÄ chunking/            (Step 5: Refactor from root)
‚îÇ   ‚îî‚îÄ‚îÄ engine.py
‚îÇ
‚îú‚îÄ‚îÄ summarization/       (Step 6: Refactor from root)
‚îÇ   ‚îî‚îÄ‚îÄ progressive.py
‚îÇ
‚îî‚îÄ‚îÄ ai/                  (Model integrations)
    ‚îî‚îÄ‚îÄ ollama_model_manager.py
```

**Current Status:** Steps 1-2 complete in `src/extraction/`. Steps 3-6 will be refactored into this structure in v3.0.

## Phase 1 Accomplishments

### Core Document Processing ‚úÖ
‚úÖ Multi-format support: PDF (digital & scanned), TXT, RTF
‚úÖ OCR integration with Tesseract
‚úÖ Dictionary-based confidence scoring for text quality
‚úÖ Smart text normalization with legal document preservation (Step 2)

### Advanced Text Cleaning ‚úÖ
‚úÖ De-hyphenation across line breaks
‚úÖ Page number removal (multiple formats)
‚úÖ Legal header preservation (SUPREME COURT, PLAINTIFF, etc.)
‚úÖ Line filtering (removes short/junk lines while keeping important content)
‚úÖ Whitespace normalization

### Legal Document Features ‚úÖ
‚úÖ Case number extraction (Federal, NY Index, Docket numbers)
‚úÖ Automatic case number detection and storage in results
‚úÖ Legal keyword recognition for document classification

### Error Handling & UX ‚úÖ
‚úÖ Specific error messages (password-protected PDFs, corruption, permissions)
‚úÖ File type validation with helpful format suggestions
‚úÖ Progress callback support for UI integration
‚úÖ Debug mode with performance timing

### Development & Testing ‚úÖ
‚úÖ 24 comprehensive unit tests (100% passing)
‚úÖ Command-line interface for standalone use
‚úÖ Session-start hook for Claude Code browser
‚úÖ Complete documentation
‚úÖ All code on GitHub

<h2>Phase 2.1 - UI Refactor Accomplishments</h2>

<h3>Desktop Application ‚úÖ</h3>
‚úÖ Refactored main application window to use CustomTkinter
‚úÖ Created a native-style menubar with File and Help dropdowns
‚úÖ File selection dialog is functional

<h3>UI Widgets ‚úÖ</h3>
‚úÖ Refactored `FileReviewTable`, `AIControlsWidget`, and `SummaryResultsWidget` to use CustomTkinter components
‚úÖ Integrated the new widgets into the main window layout

<h3>Concurrency ‚úÖ</h3>
‚úÖ Refactored background workers to use standard Python `threading` and `queue`
‚úÖ UI remains responsive during background file processing
‚úÖ Progress updates are successfully sent from worker threads to the UI
