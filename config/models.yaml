# Model-specific configurations
#
# context_window: The theoretical maximum context size of the model in tokens.
# max_input_tokens: A safe, practical limit for the number of tokens to send to the model for a single summarization task. 
#                   This should be less than the context_window to leave room for the prompt instructions and the generated output.

models:
  gemma3:1b:
    context_window: 8192
    max_input_tokens: 4096
  
  # Example for a future smaller model like Phi-3 Mini
  phi3:mini:
    context_window: 4096
    max_input_tokens: 2048

  # Example for a future larger model
  gemma:7b:
    context_window: 8192
    max_input_tokens: 6144
